# 1st Phorm Meme Seeding Tracker - Setup Guide

## Quick Start

### 1. Install & Deploy Convex

```bash
cd "/Users/wsnh/adley : phorm"
npm install
npx convex dev
```

This will:
- Prompt you to login/create a Convex account
- Create a new project
- Deploy your backend
- Give you a deployment URL like `https://xyz-123.convex.cloud`

### 2. Set Your Apify API Token

```bash
npx convex env set APIFY_API_TOKEN your_apify_api_token_here
```

Get your token from: https://console.apify.com/account/integrations

### 3. Update Frontend

In `index.html`, find this line near the top of the `<script>` section:

```javascript
const CONVEX_URL = null;
```

Change it to your deployment URL:

```javascript
const CONVEX_URL = 'https://your-deployment.convex.cloud';
```

### 4. Seed the Database

Open the tracker with `?admin=true`:
```
http://localhost:3000?admin=true
```

Click **"ğŸ“¥ Seed Posts to DB"** to load all Instagram URLs.

### 5. Run First Scrape

Click **"ğŸ”„ Run Instagram Scrape"** to fetch real stats from Instagram via Apify.

---

## How It Works

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â”€â”€â”€â”€â–¶â”‚    Convex       â”‚â”€â”€â”€â”€â–¶â”‚    Apify        â”‚
â”‚   (index.html)  â”‚â—€â”€â”€â”€â”€â”‚   (Backend)     â”‚â—€â”€â”€â”€â”€â”‚   (Scraper)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Real-time              Database              Instagram API
    Subscriptions          + Cron Jobs
```

### Data Flow

1. **Posts are seeded** from the hardcoded list in `convex/seed.ts`
2. **Apify scrapes Instagram** every 6 hours (or manually triggered)
3. **Convex stores results** and pushes updates to frontend in real-time
4. **Frontend auto-updates** - no refresh needed!

### Scheduled Jobs

| Job | Frequency | Description |
|-----|-----------|-------------|
| `scrape-instagram-stats` | Every 6 hours | Scrapes all posts via Apify |

---

## Admin Panel

Add `?admin=true` to URL to show admin controls:

| Button | Action |
|--------|--------|
| ğŸ“¥ Seed Posts to DB | Load all IG URLs into database |
| ğŸ”Œ Test Apify Connection | Verify API token works |
| ğŸ”„ Run Instagram Scrape | Manually trigger scrape |
| ğŸ“Š View Scrape History | See recent job results |
| ğŸ” View Last Results | Debug Apify response data |

---

## Adding New Posts

Edit `convex/seed.ts` and add URLs to the `CAMPAIGN_POSTS` array:

```typescript
const CAMPAIGN_POSTS = [
  "https://www.instagram.com/reel/ABC123/",
  "https://www.instagram.com/reel/DEF456/",
  // Add new URLs here
];
```

Then run seed again from admin panel.

---

## Apify Details

**Actor:** `apify~instagram-post-scraper`

**Input format:**
```json
{
  "username": [
    "https://www.instagram.com/reel/ABC123/",
    "https://www.instagram.com/reel/DEF456/"
  ],
  "resultsLimit": 100
}
```

**Cost:** ~$0.25-0.50 per 100 posts scraped

---

## Troubleshooting

### "Convex not configured"
Update `CONVEX_URL` in index.html

### "APIFY_API_TOKEN not set"
Run: `npx convex env set APIFY_API_TOKEN your_token`

### Posts not updating after scrape
- Check Convex dashboard logs
- Click "View Last Results" to see raw Apify data
- Verify shortcodes match between DB and Apify response

### Scrape timing out
- Apify may take 5-15 minutes for large batches
- Check job status in "View Scrape History"

---

## Files

```
â”œâ”€â”€ index.html           # Frontend with Convex real-time client
â”œâ”€â”€ package.json         # Dependencies
â”œâ”€â”€ convex/
â”‚   â”œâ”€â”€ schema.ts        # Database schema
â”‚   â”œâ”€â”€ posts.ts         # Post queries & mutations
â”‚   â”œâ”€â”€ seed.ts          # Seed data + add post functions
â”‚   â”œâ”€â”€ apify.ts         # Apify scraper integration
â”‚   â”œâ”€â”€ scrapeJobs.ts    # Job tracking
â”‚   â””â”€â”€ crons.ts         # 6-hour scheduled scrape
â””â”€â”€ SETUP.md             # This file
```
